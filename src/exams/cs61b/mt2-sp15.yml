course: 'cs61b'
ref: 'mt2-sp15'

type: 'mt2'
term: 'sp15'
prof: 'Hug'

questions: {
  'q1': 'Miscellaneous',
  'q2': 'Underwater Communications',
  'q3': 'Controlling a Car',
}

parts: {
  'q1': 4,
  'q2': 3,
  'q3': 1,
  'q4': 3,
  'q5': 5,
  'q6': 5,
  'q7': 1,
  'q8': 1,
  'q9': 1,
  'q10': 1,
  'q11': 3
}

q1_1: |
  # 1. Basic Operations (6 points)
  a. **To the right of the BST below**, draw a BST that results if we delete $20$ from the BST. You should use the deletion procedure discussed in class (i.e. no more than $4$ references should change).
  <hr class="s2" />
  ![bst](/img/cs61b/mt2-sp15-q1-1.png)

q1_1_s: |
  Either of the two trees in red below are correct. In the left case, we‚Äôve chosen the predecessor of $20$, i.e. $19$, as the new root. In the right, we‚Äôve chosen the successor.
  ![bst](/img/cs61b/mt2-sp15-q1-2.png)

q1_2: |
  b. **To the right of the `minHeap` below**, draw the `minHeap` that results if we delete the smallest item from the `minHeap`.
  <hr class="s2" />
  ![minheap](/img/cs61b/mt2-sp15-q1-3.png)

q1_2_s: |
  The only correct answer if we use the procedure from class is the minHeap shown to the right.
  <hr class="s2" />
  ![minheap](/img/cs61b/mt2-sp15-q1-4.png)

q1_3: |
  c. **To the right of the External Chaining Hash Set below**, draw the External Chaining Hash Set that results if we insert $5$. As part of this insertion, you should also resize from $4$ buckets to $8$ (in other words, the implementer of this data structure seems to be resizing when the load factor reaches $1.5$). Assume that we‚Äôre using the default `hashCode` for integers, which simply returns the integer itself.
  <hr class="s2" />
  ![hash set](/img/cs61b/mt2-sp15-q1-5.png)

q1_3_s: |
  The correct answer is shown to the right. All items must appear in exactly the bucket shown (though $10$ and $18$ could be in reverse order).
  <hr class="s2" />
  ![hash set](/img/cs61b/mt2-sp15-q1-6.png)

q1_4: |
  d. Draw a valid Weighted Quick Union object that results after the following calls to connect: `connect(1, 4), connect(2, 3), connect(1, 3), connect(5, 1)`. Don‚Äôt worry about the order of the arguments to each connect call, we‚Äôll accept any reasonable convention.

q1_4_s: |
  There are many correct answers depending on your convention for order of arguments. The most important points are that when you connect items, that you‚Äôre only connecting the roots of each subtree to other roots, and that when you connect $5$ to the weight $4$ tree, that the $1$ points directly at the root of that tree. One example solution is given below. Giving an answer in terms of an `id[]` array was also acceptable.
  <hr class="s2" />
  ![quick union](/img/cs61b/mt2-sp15-q1-7.png)

q2_1: |
  # 2. Asymptotics (5 points)
  a. Suppose we run experiments to understand the runtime performance of the add method of the `PotatoSack` class. The runtime as a function of $N$ (the number of inserts) is shown below. Using the technique from the asymptotics lab, **approximate** the empirical run time in **tilde notation** as a function of $N$. As a reminder, in that lab, we assumed that the runtime is $aN^b$, and found $a$ and $b$. Do not leave your answer in terms of logarithms. Your $a$ and $b$ must be within $25$% of our answers. Use only the data points that you expect to give the best approximation of the asymptotic behavior of the algorithm. Hint: To double check your answer, plug in $N=1000$ and see if the runtime prediction seems sensible.
  <hr class="s2" />
  ![table](/img/cs61b/mt2-sp15-q2-1.png)

q2_1_s: |
  **Answer:** $0.001N^2$.
  <hr class="s2" />
  Since we are interested in asymptotic behavior, we use the largest data points. To calculate $b: \text{log}_2(9.97/2.5)$ is approximately $2$. Then we have that $9.97 = a100^2$, so $a = 0.001$. We can double check by plugging in $N=1000$, getting $1000$ seconds, which $100 \times$ the time as we‚Äôd expect from $10 \times$ing the input to a quadratic algorithm.

q2_2: |
  b. Suppose we measure the performance of a collection $X$, and find that inserting $N$ items takes $\Theta(N^2)$ time. For each of the following, **circle the collection type if it is possible** for that collection to take $\Theta(N^2)$ time to insert $N$ items on a worst-case input, and **cross out the collection type if it is impossible**. Assume that each is correctly implemented. Either circle or cross out every answer.
  ![table](/img/cs61b/mt2-sp15-q2-2.png)

q2_2_s: |
  ![table](/img/cs61b/mt2-sp15-q2-3.png)
  <hr class="s2" />
  NOTE: You will lose points if an item is neither circled nor crossed out.

q2_3: |
  c. If we have two correct algorithms for solving the same problem that use the exact same amount of memory, but have worst-case runtimes that are $\Theta(N)$ and $\Theta(N^2)$, is it always better to use the algorithm that is $\Theta(N)$? If so, why? If not, why not?

q2_3_s: |
  Best Answers:
  - For small $N$, $\Theta(N^2)$ could be faster than $\Theta(N)$ if there is a smaller coefficient for $\Theta(N^2)$. This comes up, for example, in matrix multiplication algorithms (more during the last week of class).
  - The worst-case may only occur for specific inputs that we don‚Äôt care about. This is, for example, what we observe with Quicksort, which is worst case $\Theta(N^2)$, but often used in lieu of Mergesort which is worst case $\Theta(N \; \text{log} \; N)$.

q3_1: |
  # 3. Exceptions (2 points)
  One common software engineering strategy is to create log files that can be manually examined if something goes wrong. In the code below, the writeToLog method writes the given argument to some log. What are the contents of the log file after the code below is executed? You may not need all of the lines provided.
  ```
  public class QuestionThree {
      public static void printTenth(int[] a) {
          try {
              writeToLog(a[10]);
          } catch (IndexOutOfBoundsException e) {
              writeToLog("No tenth item available!");
              throw(e);
          }
      }

      public static void main(String[] args) {
          printTenth(new int[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10});
          printTenth(new int[]{0, 1, 2, 3});
          printTenth(new int[]{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10});
      }
  }
  ```
  ________________________________
  <hr class="s1" />
  ________________________________
  <hr class="s1" />
  ________________________________
  <hr class="s1" />
  ________________________________
  <hr class="s1" />
  ________________________________

q3_1_s: |
  _10____________________________
  <hr class="s1" />
  _No tenth item available!_____
  <hr class="s1" />
  ________________________________
  <hr class="s1" />
  ________________________________
  <hr class="s1" />
  ________________________________

q4_1: |
  # 4. TreeTime (5 points)
  a. True or false: If $A$ and $B$ are 2-3-4 trees with the same exact elements, they must be identical. If true, justify with a short (**less than 20 words**) explanation. If false, provide a counter-example.

q4_1_s: |
  Insert 1,2,3,4,5 (pushing up the 2 upon inserting the 4).
  <hr class="s1" />
  Insert 2,3,4,5,1 (pushing up the 3 upon inserting the 5).
  <hr class="s2" />
  These 2 sequences of inserts produce different trees.

q4_2: |
  b. Draw the red-black tree which results after calling `insert(25)` on the red-black tree shown below. We denote red links with dashed lines and black links with normal lines. Please use the same notation in your answer. **You should draw your tree in the empty space to the right of the given tree. Do not modify the given figure.** Hint: Every 2-3 tree corresponds to exactly one LLRB, and every LLRB corresponds to exactly one 2-3 tree.
  ![rbtree](/img/cs61b/mt2-sp15-q4-1.png)

q4_2_s: |
  ![rbtree](/img/cs61b/mt2-sp15-q4-2.png)
  <hr class="s2" />
  To achieve this answer, we can start by converting the LLRB into a 2-3 tree (show below, to the left), then inserting 15 (result below, to the right). Then converting back into an LLRB.
  <hr class="s2" />
  ![23 tree](/img/cs61b/mt2-sp15-q4-3.png)

q4_3: |
  c. Suppose that we want to write a method `sumDescendants`, which replaces the value of each node in a tree with the sum of all of its descendants' values (not including itself), and then returns the sum of its original value (before being changed) plus all of its descendants‚Äô values.
  <hr class="s2" />
  For example, given the tree on the left, `sumDescendants` on node $6$ would return $42$ and change the tree to look like the one on the right (since $36 + 6 = 42$).
  <hr class="s2" />
  ![binarytree](/img/cs61b/mt2-sp15-q4-4.png)
  <hr class="s2" />
  Fill in the `sumDescendants` method. You may not need all lines. Do not use more lines.
  ```
  public class TreeNode {
      public TreeNode left, right;
      public int value;
      public TreeNode(int n) {
          value = n;
      }
      /* Replaces value with sum of all of its descendants' values. */
      public int sumDescendants() {
          if (left == null && right == null) {
              int oldVal = value;
              ___________________________;
              return oldVal;
          }
          else {
              _______________________________
              _______________________________
              _______________________________
              _______________________________
              _______________________________
              _______________________________
              _______________________________
              _______________________________
              int oldVal = value;
              ___________________________;
              return oldVal + value;
          }
      }
  }
  ```

q4_3_s: |
  ```
  public class TreeNode {
      public TreeNode left, right;
      public int value;
      public TreeNode(int n) {
          value = n;
      }
      /* Replaces value with sum of all of its descendants' values. */
      public int sumDescendants() {
          if (left == null && right == null) {
              int oldVal = value;
              value = 0;
              return oldVal;
          }
          else {
              int leftSum = 0; int rightSum = 0;
              if (left != null) {
                  leftSum = left.sumDescendants();
              }
              if (right != null) {
                  rightSum = right.sumDescendants();
              }
              int oldVal = value;
              value = leftSum + rightSum;
              return oldVal + value;
          }
      }
  }
  ```

q5_1: |
  # 5. Code Analysis (2.5 points)
  For each of the pieces of code below, give the runtime in $\Theta(¬∑)$ notation as a function of the given parameters. Your answer should be simple, with no unnecessary leading constants or unnecessary summations.
  ```
  public static void f1(int n) {
      for (int i = 0; i < 2*n; i += 1) {
          System.out.println("hello");
      }
  }
  ```

q5_1_s: |
  **Answer:** $\Theta(n)$.

q5_2: |
  ```
  public static void f2(int n) {
      if (n == 0) { return; }
      f2(n/2);
      f1(n);
      f2(n/2);
  }
  ```

q5_2_s: |
  **Answer:** $\Theta(n \; \text{log} \; n)$.
  <hr class="s1" />
  Note: The problem above is the same pattern as mergesort.

q5_3: |
  ```
  public static void f3(int n) {
      if (n == 0) { return; }
      f3(n/3);
      f1(n);
      f3(n/3);
      f1(n):
      f3(n/3);
  }
  ```

q5_3_s: |
  **Answer:** $\Theta(n \; \text{log} \; n)$.
  <hr class="s1" />
  Note: The problem above is the same pattern as mergesort, but now with 3 subproblems, all of size $N/3$.

q5_4: |
  ```
  public static void f4(int n) {
      if (n == 0) { return; }
      f4(n-1);
      f1(17);
      f4(n-1);
  }
  ```

q5_4_s: |
  **Answer:** $\Theta(2^n)$.

q5_5: |
  ```
  public static void f5(int n, int m) {
      if (m <= 0) {
          return;
      } else {
          for (int i = 0; i < n; i += 1) {
              f5(n, m-1);
          }
      }
  }
  ```

q5_5_s: |
  **Answer:** $\Theta(n^m)$.

q6_1: |
  # 6. The Right Tool for the Job (6 points)
  **For each of the five tasks below, pick <u>one or two</u> data structures and describe very briefly (in 20 words or less) how you‚Äôd use those data structures to solve the problem.** You should select from the following Java Collections: `TreeMap, TreeSet, HashMap, HashSet, LinkedList, ArrayList, HeapMinPQ, HeapMaxPQ, WeightedQuickUnion. TreeMap` and `TreeSet` utilize red-black trees. `HashMap` and `HashSet` utilize external chaining.
  <hr class="s2" />
  You should pick the data structure (or structures) that are best suited to the task in terms of performance and ease-of-use, taking into account the specific types of inputs listed in each problem. For most problems, you should need only one data structure. If some part of the problem seems ambiguous, state the assumptions that you‚Äôre making.
  <hr class="s2" />
  **For each task, also give the runtime in $O( \cdot )$ notation. Give the tightest bound you can** (e.g. don't just write $O(n^{n^{n^n}})$, which while technically correct, isn‚Äôt very informative).
  <hr class="s2" />
  **Task 1)** Read in a text file and print all of the unique words that appear. The words should be printed in alphabetical order. Give the $O( \cdot )$ runtime in terms of $N$, the number of words in the file. Remember, you must provide either a choice of either <u>one or two</u> data structures, as well as a short (< 20 word) description of how you‚Äôd use those data structures to solve the problem.

q6_1_s: |
  The simplest and most natural choice is a `TreeSet`. Inserting all items takes $O(N \; \text{log} \; N)$ time. Iteration (which performs an in-order traversal) takes $O(N)$ time. `TreeMap` also works, but it is awkward to use a `Map` instead of a `Set` since you‚Äôre not really using the key-value mapping feature (and instead are just using containsKey). However, performance and code complexity for a `TreeMap` would be identical, despite the aesthetic grossness.
  <hr class="s2" />
  Alternately, one could use a `HashSet`, with insertion taking $O(N)$ time (assuming we don‚Äôt have pathologically colliding Strings). However, we‚Äôd then need to somehow get the items in the `HashSet` in sorted order. The simplest way would be to stick them in an array and sort it, in $O(N \; \text{log} \; N)$ time, but other possibilities work as well. This solution is inferior to `TreeSet` in both performance and complexity for the programmer. It was not correct to create a HashMap that mapped from `hashCode` to `String` ‚Äì what you were thinking of was a `HashSet` (a map from `hashCode` to `String` doesn‚Äôt detect duplicates).

q6_2: |
  **Task 2)** Given two Collections of very long `Strings` (e.g. DNA Sequences of tens of thousands of characters or more), observed and known, check each `String` in observed to see if it exactly matches any `String` in known. observed is an `ArrayList<String>` of size $N_O$. For this task, choose a data structure for known. Give the $O( \cdot )$ runtime in terms of $N_O$ and $N_K$, where $N_K$ is the size of known. Assume that the `Strings` in known are highly dissimilar from each other. Assume also that known has already been constructed.

q6_2_s: |
  For this particular case, a `TreeSet` will vastly outperform a HashSet on any real dataset, due to the fact that we can avoid computing the hash value of any particular string. Runtime will be $O(N_O \; \text{log} \; N_K)$.
  <hr class="s2" />
  A `HashSet` will have runtime $O(N_O)$, which while asymptotically faster will be inferior in practice since $\text{log}\; N_K$ is much smaller than the length of a `String`. This is a very subtle but interesting technical point that was allocated little credit, but which it is nonetheless good to be aware of. I suspect very few students made this realization.
  <hr class="s2" />
  More verbosely, we can compare `TreeSet` and `HashSet` performance would be to consider the runtimes as a function that also include the string length $M$. For a `HashSet`, the runtime will be $O(N_OM)$, due to the cost of computing a `String .hashCode()`. By contrast, a `TreeSet` will only compare the first few characters (since each string is highly dissimilar from every other string) at each level of the tree. For simplicity, let‚Äôs call represent this number of characters by a function $c(M)$. This means that the runtime for a `TreeSet` will be $O(N_O \; \text{log} \; N_Kc(M))$. Given that $M$ is in the tens of thousands, we can reasonably assert that $M > \text{log}N_kc(M)$ for any real dataset.
  <hr class="s2" />
  One workaround for this would be to create a custom hash function which only uses only some characters of a `String`.

q6_3: |
  **Task 3)** Read in a large number of grayscale images, and display all of the unique images. The images may be displayed in any order. Each image is stored as a `Picture` object that contains image data stored as an `int[][] variable`, all of which are $512 \; \times \; 512$ (i.e. have a width and height of $512$). Give the $O( \cdot )$ runtime in terms of $N$, the number of images.

q6_3_s: |
  The most natural approach is a `HashSet`. In this case, the runtime would be simply $O(N)$, assuming that our `hashCode` evenly distributes all items. A `TreeSet` is also a reasonable choice, and may actually be faster for the same reasons in task $2$; however, in this case, the `hashCode` was not specified, so we cannot say for certain which data structure will do better. If we use a `TreeSet`, the runtime is $O(N \; \text{log} \; N)$, and the `Picture` class would need to implement the `Comparable` interface (which is a bit awkward for a `Picture` class).
  <hr class="s2" />
  Note: The original version of the midterm simply stated that the picture was stored as an `int[][]`. The intention was that this `int[][]` was wrapped in some sort of object, otherwise usage of a `TreeSet` or `HashSet` would fail. `TreeSet` would fail since `int[][]` are not `Comparable`, and `HashSet` would fail because Java would use the default equals method for arrays, which only compares using == instead of actually comparing elements. An efficient solution to this interpretation of the problem would require creation of a container class like `Picture` to allow usage of a `TreeSet` or `HashSet`.
  <hr class="s2" />
  Multiple different runtimes were accepted because of different possible interpretations of the runtime (runtime of just a single image or runtime of all of the $N$ images?)
  <hr class="s2" />
  Common answers:
  - `HashMap` or `TreeMap`. It‚Äôs unnecessary to use a mapping because you can store the image directly. There‚Äôs no need to count instances, hence a `Set` structure is better. A mapping works if you properly store the image as the key. Using the `.hashCode` value as the key only works if the hash code is a perfect hash, or else non-duplicates might be considered duplicate.
  - `ArrayList` or `LinkedList`. A less efficient solution is to use a list. For every image, check to see if it‚Äôs equal to all previously added lists, and if it‚Äôs unique, then add it to the list. You must have specified the check for uniqueness in order to receive any points at all (or else you aren‚Äôt satisfying the job).

q6_4: |
  **Task 4)** Store the email address for each username on our website, which is devoted to publishing articles about computer hackers being terrible people. Usernames and email addresses are both `Strings` (and thus use the default `.hashCode` and `.compareTo` methods). Our website allows anybody to register any number of accounts. Give the $O( \cdot )$ runtime needed to add each user in terms of $N$, the current number of users.

q6_4_s: |
  A quick glance indicates that we‚Äôd want to use either a `TreeMap` or a `HashMap`. We did not specify whether you‚Äôd want to map from username to email address or vice versa, but this detail is irrelevant.
  <hr class="s2" />
  Here, we‚Äôre forcing you to use the (well known) `.hashCode` for `Strings`. This means that a community of hackers trying to ruin the performance of our website could create a bunch of usernames that all hash to the same `hashCode`. This would eventually cripple our site. To safely use a hash table, we would have to either use a fancier hashing strategy (i.e. not `HashMap` which is just external chaining), some sort of secure hash function.
  <hr class="s2" />
  An even better answer would be a `TreeSet`, which is not vulnerable to such attacks, though the performance in the absence of such attacks would be somewhat slower.
  <hr class="s2" />
  For a `HashMap`, the runtime would be $O(1)$ assuming no collisions, $O(N)$ assuming many collisions, and for a `TreeSet`, it would be $O(\text{log}\;N)$.

q6_5: |
  **Task 5)** *Erweitetern Netzwerkis* a new German minimalist social network that provides three functions. Its user base is capped at a maximum of $K$ users, where $K$ is some large constant known at runtime:
  - Neu: Enter a username and click the Neu button. Create a new user with this username if space is still available.
  - Befreunden: Enter two usernames and click the befreunden button. The users are now friends. If one of the users does not exist, ignore the command.
  - Erweiterten Netzwerk: Enter two usernames and click the Erweitertern Netzwerk button. The website prints true if there is a chain of user friendships that connect the users.

  <hr class="s2" />
  Your Neu, Befreunden, and Erweiterten Netzwerk commands must run in $O(\text{log} \; N)$ time in the worst case. Give the $O( \cdot )$ runtime in terms of $N$, the number of users at the time the command was executed. Assume that $K > N$.

q6_5_s: |
  To track connectedness, we use a `WeightedQuickUnion`. Since the connect operation of `WeightedQuickUnion` requires integer arguments, we also need a map from username to id (for example a `HashMap`, though a `TreeMap` would be fine as well if we‚Äôre worried about collisions). In this case, we have the following runtimes:
  - Neu: $O(1)$ for adding to a `HashMap`.
  - Befruenden: $O(1)$ to do lookups in a `HashMap`. $O(\text{log} \; N)$ to do a connect call. Overall then $O(\text{log} \; N)$.
  - Erweiterten Netzwerk: $O(1)$ to do lookups, $O(\text{log} \; N)$ to do `isConnected` call. Overall then $O(\text{log} \; N)$.

q7_1: |
  # 7. GorpyCorp (2 points)
  Gorpy McGorpGorp is the founder of GorpyCorp. GorpyCorp is organized into several independent teams known as ‚ÄùCircles‚Äù, where every Circle has a leader known as a ‚Äúlead link‚Äù. Gorpy uses the following data structure to record the members and teamName of each Circle:
  ```
  public class Circle {
      HashSet< Member > members;
      String teamName;

      public int hashCode() {
          int hashCode = 0;
          for (Member m : members) {
              hashCode = hashCode * 31 + m.hashCode();
          }
          hashCode = hashCode + teamName.hashCode();
          return hashCode;
      }

      public int compareTo(Circle other) {
          if (this.members.size() == other.members.size())
              return this.teamName.compareTo(other.teamName);
          return this.members.size() - other.members.size();
      }

      public void addMember(Member newMember) {
          members.add(newMember);
      }

      ...
  }
  ```
  Rather than storing the leader of each `Circle` inside of the `Circle` object, Gorpy instead decides to create a separate `HashMap` defined below, which allows a programmer to look up the lead link of each circle.
  ```
  HashMap< Circle, Member >leadLinks;
  ```
  What is the most significant problem with Gorpy‚Äôs usage of a `HashMap`? If he uses a `TreeMap` instead of a `HashMap`, will this problem be fixed? Why or why not?

q7_1_s: |
  The problem is that `Circle` objects are mutable. If we insert them into a `HashMap`, and then later change the `Circle`, then we will no longer be able to find the `Circle` when we try to look it up in the `HashMap`. For example:
  <hr class="s2" />
  ```
  Circle x = someMethodThatCreatesACircle();
  leadLinks.put(x, Alice);
  x.addMember(Doug);
  leadLinks.get(x);
  ```
  <hr class="s2" />
  The problem here is that the last line will not find x, since the `hashCode` will (with very high probability) calculate a different bucket than the one that x is actually in.
  <hr class="s2" />
  If we use a `TreeMap`, the code breaks, because the `Circle` class does not implement Comparable. However, even if it did, a very similar problem occurs due to mutability: If a circle adds a member, it would no longer be in the correct location in the `TreeMap` and we would be unable to find it when we do the usual BST search.
  <hr class="s2" />
  Less correct answer: The `Circle` class does not appear to implement equals (though it may be in the ... section). This means that Java will use the default .equals method for determining whether an item is in the `HashMap`. Thus two identical `Circles` (same name, same members) could coexist in the `HashMap`, leading to confusion. In this case, `TreeMap` would resolve the issue since it can use the compareTo method to resolve equality.
  <hr class="s2" />
  Even less credit answer: A `HashMap` may have too many collisions leading to long chains. The given `hashCode` should be fairly robust, and there are more significant problems with the implementation. In this case, a `TreeMap` would resolve this issue, since `TreeMaps` are always balanced.

q8_1: |
  # 8. By the Numbers (3.5 points)
  For each of the scenarios below, give the correct numbers. On each line, **in the first blank write the minimum, and in the second blank write the maximum**. We define the height as the maximum number of links from the root to a leaf (so the tree in problem 1b has a height of 3, not 4). Each blank is worth 0.25 points (so don‚Äôt burn all your time trying out bajillions of examples).
  <hr class="s2" />
  - The minimum and maximum height of a BST with $15$ nodes.
  - The minimum and maximum height of a Quick Union object with $15$ elements where $d(a, b)$ returns true for every pair of items.
  - The minimum and maximum height of a Weighted Quick Union object with $15$ elements where `isConnected(a, b)` returns true for every pair of items.
  - The minimum and maximum height of a 2-3-4 Tree containing $15$ items. Recall that a node in a 2-3-4 tree may have $1, 2,$ or $3$ items inside.
  - The minimum and maximum height of an LLRB set containing $15$ items.
  - The minimum and maximum height of a binary heap containing $15$ items.
  - The minimum and maximum number of items in a single bucket for a chaining hash table with $30$ items and $15$ buckets (i.e. with a load factor of $2$).

q8_1_s: |
  - The minimum and maximum height of a BST with $15$ nodes. **3, 14**
  - The minimum and maximum height of a Quick Union object with $15$ elements where d(a, b) returns true for every pair of items. **1, 14**
  - The minimum and maximum height of a Weighted Quick Union object with $15$ elements where `isConnected(a, b)` returns true for every pair of items. **1, 3**
  - The minimum and maximum height of a 2-3-4 Tree containing $15$ items. Recall that a node in a 2-3-4 tree may have $1, 2,$ or $3$ items inside. **1, 3**
  - The minimum and maximum height of an LLRB set containing $15$ items. **3, 5**
  - The minimum and maximum height of a binary heap containing $15$ items. **3, 3**
  - The minimum and maximum number of items in a single bucket for a chaining hash table with $30$ items and $15$ buckets (i.e. with a load factor of $2$). **0, 30**

  <hr class="s2" />
  **Justification:**
  <hr class="s2" />
  **The minimum and maximum height of a BST with $15$ nodes.**
  <hr class="s2" />
  Minimum is a perfectly balanced binary search tree (‚Äúbushy‚Äù tree). Thus, the height is equivalent to floor($\text{log}_2(15)$) = $3$. Maximum is a perfectly spindly tree, so the height is $14$.
  <hr class="s2" />
  **The minimum and maximum height of a Quick Union object with $15$ elements where `isConnected(a, b)` returns true for every pair of items.**
  <hr class="s2" />
  Minimum case is when you connect every node $a$ to some node $b$ to yield a height of $1$. Maximum case is when you effectively form a linked list from connecting each node, i.e. you connect with your ‚Äúprevious‚Äù node in some ordering, yielding a height of $14$.
  <hr class="s2" />
  ![bst](/img/cs61b/mt2-sp15-q8-1.png)
  <hr class="s2" />
  **The minimum and maximum height of a Weighted Quick Union object with $15$ elements where `isConnected(a, b)` returns true for every pair of items.**
  <hr class="s2" />
  Minimum case is as before: you connect every node ùëé to some node ùëè to yield a height of $1$. Maximum case, however, will link things together such that the shorter tree is joined with the larger one to minimize the height. Thus, the maximum case is now floor($\text{log}_2 15) = 3$.
  <hr class="s2" />
  **The minimum and maximum height of a 2-3-4 tree containing $15$ items. Recall that a node in a 2-3-4 tree may have $1, 2,$ or $3$ items inside.**
  <hr class="s2" />
  The minimum height possible is if each node is as full as possible: if they each contain $3$ items. This means that you will have up $15/3 = 5$ nodes. This corresponds with a height of $\text{log}_4 15 = 1$. The maximum height possible is if each node is as empty as possible: if they each contain $1$ item. This means there are $15$ nodes and thus $\text{log}_2 15 = 3$.
  <hr class="s2" />
  ![weightedquickunion](/img/cs61b/mt2-sp15-q8-2.png)
  **The minimum and maximum height of an LLRB set containing $15$ items.**
  <hr class="s2" />
  The minimum case is when we just have a tree full of $2$-nodes. This gives us a height of $\text{log}_ 15 = 3$. The maximum case is when we try to stuff as many $3$-nodes as possible onto the left of the corresponding $2-3$ tree, because we know that each $3$-node will add a level into the tree.
  <hr class="s2" />
  ![llrb](/img/cs61b/mt2-sp15-q8-3.png)
  <hr class="s2" />
  ![llrb](/img/cs61b/mt2-sp15-q8-4.png)
  <hr class="s2" />
  **The minimum and maximum height of a binary heap containing $15$ items.**
  <hr class="s2" />
  A binary heap is perfectly balanced, so the minimum and maximum height are both $\text{log}_2 15 = 3$.
  <hr class="s2" />
  **The minimum and maximum number of items in a single bucket for a chaining hash table with $30$ items and $15$ buckets. (i.e. with a load factor of $2$)**
  <hr class="s2" />
  Consider the case where we have a lousy hash function that hashes everything to the same bucket. Thus, we have a minimum of $0$ items in one bucket and a maximum of $30$ items in a bucket.

q9_1: |
  # 9. PNH (0 Points)
  Who was the agoyatis of Mr. Conchis? Hermes

q9_1_s: |
  Hermes

q10_1: |
  # 10. Quartiler (2.5 points)
  Warning: This problem is particularly challenging. Do not start until you feel like you‚Äôve done everything else you can. We will be award very little partial credit for this problem. Solutions which are correct but do not meet our time and space requirements (below) will be not be awarded credit.
  <hr class="s2" />
  The interface for the `Quartiler` interface is shown below.
  ```
  public interface Quartiler< <b>Item</b> > {
      /* Adds an <b>item</b> to the Quartiler. */
      public add(<b>Item</b> x);
      /* Gets the <b>item</b> that is closest to 75th percentile. */
      public getTopQuartile();
      /* Deletes the <b>item</b> that is closest to the 75th percentile. */
      publci deleteTopQuartile();
  }
  ```
  For example, if we add the integers $1$ through $100$, then `getTopQuartile` will return $75$. If we instead add the integers $1$ through $4$ to an empty `Quartiler`, then `getTopQuartile` will return $3$. If there is a tie (e.g. if the Quartlier contains the integers $1$ through $6$), then ties may be broken arbitrarily. Design a data structure that supports these operations in amortized $O(\text{log} \; N)$ time and $O(N)$ space.
  <hr class="s2" />
  a. Describe your data structure as concisely as possible while still including all relevant details. If you use existing data structure (for example, those listed in problem 6) as components, give them by name.

q10_1_s: |
  Note, we did not fully define `Quartile` and our definition was non-standard. As it happens, there are multiple standards, not in agreement, about what precisely a quartile is: [http://en.wikipedia.org/wiki/Quartile](http://en.wikipedia.org/wiki/Quartile). Consequently, you may have found our implicit definition a bit odd when it came to handling things like tie-breakers. It‚Äôs not particularly important for this problem, so we did not include your tie-breaking as part of your score.
  <hr class="s2" />
  One approach is to create two heaps. One heap (`lowerHeap`) will track all values that are in the bottom 75% (not including the `topQuartile` value), and the top heap (`upperHeap`) will track all values in the top 25% (not including the `topQuartile` value). Finally, we will have a separate variable that tracks the actual `topQuartile` value.
  <hr class="s2" />
  When we insert a value, if it is larger than the `topQuartile`, we insert it into the `upperHeap`, and if it is smaller than the `topQuartiler`, we insert it into the `lowerHeap`. We enforce that the `lowerHeap` is always roughly 3 times the `upperHeap` as follows: If the `lowerHeap` is too large, we insert the `topQuartile` value into the `upperHeap`, delete the largest value from the `lowerHeap` and then move this value into the `topQuartile` variable. We do the same if the `upperHeap` becomes too large.
  <hr class="s2" />
  When we `deleteTopQuartile`, we take an item from the heap such that the same relative size invariant is maintained. For full credit on this problem, you were not required to derive the exact size invariant, particularly as quartile was not well defined. Simply stating that the lower heap should be roughly 3 times the lower heap was fine. We evaluated understanding of the invariant based on your drawing.
  <hr class="s2" />
  An alternate and more straightforward answer is to create a balanced binary search tree where each item tracks its subtree size (for example, the red black tree implementation from the book). In this case, we‚Äôd simply request the item of `rank(3*N/4)` from the tree. To find the item of `rank(3*N/4)`, traverse the tree based on the subtree sizes instead of by key comparison. Stop when you find the tree with size closest to $3\*N/4$. However, such an approach also requires that we modify our LLRB so that it can somehow accommodate duplicates. Answers that simple mention using a tree were not awarded credit (as you have to handle both duplicate finding and selecting items of a particular rank, both non-trivial problems).
  <hr class="s2" />
  One common incorrect answer is to createa `RedBlack` tree and search for the `topQuartile`, which is $\Theta(N)$ in the worst case. Unless we store the subtree sizes inside each node of the tree, we cannot find the top quartile value at any greater speed.

q11_2: |
  b. Draw your data structure after the following numbers have been added (in this order): $5, 1, 3, 2, 4, 6, 7, 8$. You only need to draw the data structure after all $8$ insertions have been completed.

q11_2_s: |
  To the left is our `bottomHeap`, and to the right our `topHeap`. We also have that `topQuartile = 6`. Note that under standard definitions of `Quartile`, we could have also had the `topQuartile = 7` (leaving `topHeap` with only one value).
  <hr class="s2" />
  ![heaps](/img/cs61b/mt2-sp15-q11-1.png)

q11_3: |
  c. Draw your data structure after a subsequent call to `deleteTopQuartile` (which will remove the 6).

q11_3_s: |
  To the letter of our strange (and implicit) definition of `topQuartile`, our data structure would be as below:
  <hr class="s2" />
  ![heaps](/img/cs61b/mt2-sp15-q11-2.png)
  <hr class="s2" />
  But for a more standard definition of `topQuartile`, it might be instead (which has the added benefit of having a nicer ratio of $2$ as opposed to $5$ in the relative sizes of the heaps):
  <hr class="s2" />
  ![heaps](/img/cs61b/mt2-sp15-q11-3.png)
